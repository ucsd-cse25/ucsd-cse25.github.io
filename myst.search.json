{"version":"1","records":[{"hierarchy":{"lvl1":"How to MyST, without being mystified üßô"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"How to MyST, without being mystified üßô"},"content":"https://‚Äãmystmd‚Äã.org‚Äã/guide‚Äã/in‚Äã-page‚Äã-execution‚Äã#skip‚Äã-to‚Äã-frontmatter\n\nA tutorial to evolve markdown documents and notebooks into structured data\n\nAuthors: Rowan Cockett1,2 Affiliations: 1Executable Books, 2 Curvenote License: CC-BY\n\nAbstract\n\nWe introduce, a set of open-source, community-driven tools for MyST Markdown (\n\nmyst.tools) designed for scientific communication, including a powerful authoring framework that supports blogs, online books, scientific papers, reports and journals articles.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"How to MyST, without being mystified üßô","lvl2":"Background"},"type":"lvl2","url":"/#background","position":2},{"hierarchy":{"lvl1":"How to MyST, without being mystified üßô","lvl2":"Background"},"content":"Scientific communication today is designed around print documents and pay-walled access to content. Over the last decade, the open-science movement has accelerated the use of pre-print services and data archives that are vastly improving the accessibility of scientific content. However, these systems are not designed for communicating modern scientific outputs, which encompasses so much more than a paper-centric model of the scholarly literature.\n\nWe believe how we share and communicate scientific knowledge should evolve past the status quo of print-based publishing and all the limitations of paper.\n\nThe communication and collaboration tools that we are building in the Project Jupyter are built to follow the FORCE11 recommendations (Bourne et al., 2012). Specifically:\n\nrethink the unit and form of scholarly publication;\n\ndevelop tools and technologies to better support the scholarly lifecycle; and\n\nadd data, software, and workflows as first-class research objects.\n\nBy bringing professional, high-quality tools for science communication into the research lifecycle, we believe we can improve the collection and preservation of scholarly metadata (citations, cross-references, annotations, etc.) as well as open up new ways to communicate science with interactive figures & equations, computation, and reactivity.\n\nThe tools that are being built by the Project Jupyter are focused on introducing a new Markup language, MyST (Markedly Structured Text), that works seamlessly with the Jupyter community to enhance and promote a new path to document creation and publishing for next-generation scientific textbooks, blogs, and lectures. Our team is currently supported by the \n\nSloan Foundation, (\n\nGrant #9231).\n\nMyST enables rich content generation and is a powerful format for scientific and technical communication. JupyterBook uses MyST and has broad adoption in publishing tutorials and educational content focused around Jupyter Notebooks.\n\nThe components behind Jupyter Book are downloaded 30,000 times a day, with 750K downloads last month.\n\nThe current toolchain used by \n\nJupyterBook is based on \n\nSphinx, which is an open-source documentation system used in many software projects, especially in the Python ecosystem. mystjs is a similar tool to \n\nSphinx, however, designed specifically for scientific communication. In addition to building websites, mystjs can also help you create scientific PDFs, Microsoft Word documents, and JATS XML (used in scientific publishing).\n\nmystjs uses existing, modern web-frameworks in place of the \n\nSphinx build system. These tools come out-of-the-box with prefetching for faster navigation, smaller network payloads through modern web-bundlers, image optimization, partial-page refresh through single-page application. Many of these features, performance and accessibility improvements are difficult, if not impossible, to create inside of the \n\nSphinx build system.\n\nIn 2022, the Executable Books team started work to document the specification behind the markup language, called \n\nmyst-spec, this work has enabled other tools and implementations in the scientific ecosystem to build on MyST (e.g. \n\nscientific authoring tools, and \n\ndocumentation systems).\n\nThe mystjs ecosystem was developed as a collaboration between \n\nCurvenote, \n\n2i2c and the \n\nExecutableBooks team. The initial version of mystjs was originally release by \n\nCurvenote as the \n\nCurvenote CLI under the MIT license, and transferred to the \n\nExecutableBooks team in October 2022. The goal of the project is to enable the same rich content and authoring experiences that \n\nSphinx allows for software documentation, with a focus on web-first technologies (Javascript), interactivity, accessibility, scientific references (e.g. DOIs and other persistent IDs), professional PDF outputs, and JATS XML documents for scientific archiving.","type":"content","url":"/#background","position":3},{"hierarchy":{"lvl1":"How to MyST, without being mystified üßô","lvl2":"MyST Project"},"type":"lvl2","url":"/#myst-project","position":4},{"hierarchy":{"lvl1":"How to MyST, without being mystified üßô","lvl2":"MyST Project"},"content":"In this paper we introduce mystjs, which allows the popular MyST Markdown syntax to be run directly in a web browser, opening up new workflows for components to be used in web-based editors, \n\ndirectly in Jupyter and in JupyterLite. The libraries work with current MyST Markdown documents/projects and can export to \n\nLaTeX/PDF, \n\nMicrosoft Word and \n\nJATS as well as multiple website templates using a \n\nmodern React-based renderer. There are currently over 400 scientific journals that are supported through \n\ntemplates, with \n\nnew LaTeX templates that can be added easily using a Jinja-based templating package, called \n\njtex.\n\nIn our paper we will give an overview of the MyST ecosystem, how to use MyST tools in conjunction with existing Jupyter Notebooks, markdown documents, and JupyterBooks to create professional PDFs and interactive websites, books, blogs and scientific articles. We give special attention to the additions around structured data, standards in publishing (e.g. efforts in representing Notebooks as JATS XML), rich \n\nfrontmatter and bringing \n\ncross-references and \n\npersistent IDs to life with interactive hover-tooltips (\n\nORCID, RoR, \n\nRRIDs, \n\nDOIs, \n\nintersphinx, \n\nwikipedia, \n\nJATS, \n\nGitHub code, and more!). This rich metadata and structured content can be used directly to improve science communication both through self-publishing books, blogs, and lab websites ‚Äî as well as journals that incorporate Jupyter Notebooks.","type":"content","url":"/#myst-project","position":5},{"hierarchy":{"lvl1":"How to MyST, without being mystified üßô","lvl2":"Features of MyST"},"type":"lvl2","url":"/#features-of-myst","position":6},{"hierarchy":{"lvl1":"How to MyST, without being mystified üßô","lvl2":"Features of MyST"},"content":"MyST is focused on scientific writing, and ensuring that citations are first class both for writing and for reading (see Figure 1).\n\n\nFigure 1: Citations are rendered with a popup directly inline.\n\nMyST aims to show as much information in context as possible, for example, Figure 2 shows a reading experience for a referenced equation: you can immediately click on the reference, see the equation, all without loosing any context -- ultimately saving you time. Head et al. (2021) found that these ideas both improved the overall reading experience of articles as well as allowed researchers to answer questions about an article 26% faster when compared to a traditional PDF!\n\n\nFigure 2: In context cross-references improve the reading experience.\n\nOne of the important underlying goals of practicing reproducibility, sharing more of the methods and data behind a scientific work so that other researchers can both verify as well as build upon your findings. One of the exciting ways to pull for reproducibility is to make documents directly linked to data and computation! In Figure 3, we are showing outputs from a Jupyter Notebook directly part of the published scientific narrative.\n\n\nFigure 3: Embedding data, interactivity and computation into a MyST article.\n\nTo drive all of these features, the contents of a MyST document needs to be well defined. This is critical for powering interactive hovers, linked citations, and compatibility with scientific publishing standards like the Journal Article Metadata Tag Suite (JATS). We have an emerging specification for MyST, \n\nmyst-spec, that aims to capture this information and transform it between many different formats, like PDF, Word, JSON, and JATS XML (Figure 4). This specification is arrived at through a community-centric MyST Enhancement Proposal (\n\nMEP) process.\n\n\nFigure 4: The data behind MyST is structured, which means we can transform it into many different document types and use it to power all sorts of exciting features!\n\nOne of the common forms of scientific communication today is through PDF documents. MyST has excellent support for creating PDF documents, using a data-driven templating library called jtex. The document in Figure 5 was created using MyST!\n\n\nFigure 5: A PDF rendering through MyST.","type":"content","url":"/#features-of-myst","position":7},{"hierarchy":{"lvl1":"How to MyST, without being mystified üßô","lvl2":"Conclusion"},"type":"lvl2","url":"/#conclusion","position":8},{"hierarchy":{"lvl1":"How to MyST, without being mystified üßô","lvl2":"Conclusion"},"content":"There are many opportunities to improve open-science communication, to make it more interactive, accessible, more reproducible, and both produce and use structured data throughout the research-writing process. The mystjs ecosystem of tools is designed with structured data at its core. We would love if you gave it a try -- learn to get started at \n\nhttps://myst.tools.","type":"content","url":"/#conclusion","position":9},{"hierarchy":{"lvl1":"How to MyST, without being mystified üßô","lvl2":"References"},"type":"lvl2","url":"/#references","position":10},{"hierarchy":{"lvl1":"How to MyST, without being mystified üßô","lvl2":"References"},"content":"Bourne, Philip E., Clark, Timothy W., Dale, Robert, De Waard, Anita, Herman, Ivan, Hovy, Eduard H., Shotton, David. (2012)‚ÄúImproving The Future of Research Communications and e-Scholarship‚Äù. FORCE11. doi:10.4230/DAGMAN.1.1.41\n\nHead, A., Lo, K., Kang, D., Fok, R., Skjonsberg, S., Weld, D. S., & Hearst, M. A. (2021, May). Augmenting Scientific Papers with Just-in-Time, Position-Sensitive Definitions of Terms and Symbols. Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 10.1145/3411764.3445648","type":"content","url":"/#references","position":11},{"hierarchy":{"lvl1":"Linking Interactive Notebooks"},"type":"lvl1","url":"/notebook","position":0},{"hierarchy":{"lvl1":"Linking Interactive Notebooks"},"content":"MyST allows you to directly include Jupyter Notebooks in your books, documents and websites.\nThis Jupyter Notebook can be rendered directly using MyST.\n\nFor example, let us import altair and create a demo of an interactive plot!\n\nimport altair as alt\nfrom vega_datasets import data\n\nsource = data.cars()\nbrush = alt.selection_interval(encodings=['x'])\npoints = alt.Chart(source).mark_point().encode(\n    x='Horsepower:Q',\n    y='Miles_per_Gallon:Q',\n    size='Acceleration',\n    color=alt.condition(brush, 'Origin:N', alt.value('lightgray'))\n).add_selection(brush)\n\nbars = alt.Chart(source).mark_bar().encode(\n    y='Origin:N',\n    color='Origin:N',\n    x='count(Origin):Q'\n).transform_filter(brush)\n\n\n\nWe can now plot the altair example, which is fully interactive, try dragging in the plot to select cars by their horsepower.\n\npoints & bars\n\n\n\n# https://matplotlib.org/stable/gallery/statistics/time_series_histogram.html#sphx-glr-gallery-statistics-time-series-histogram-py\nfrom copy import copy\n\nimport numpy as np\nimport numpy.matlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LogNorm\n\n\n\n# Make some data; a 1D random walk + small fraction of sine waves\nnum_series = 1000\nnum_points = 100\nSNR = 0.10  # Signal to Noise Ratio\nx = np.linspace(0, 4 * np.pi, num_points)\n# Generate unbiased Gaussian random walks\nY = np.cumsum(np.random.randn(num_series, num_points), axis=-1)\n# Generate sinusoidal signals\nnum_signal = int(round(SNR * num_series))\nphi = (np.pi / 8) * np.random.randn(num_signal, 1)  # small random offset\nY[-num_signal:] = (\n    np.sqrt(np.arange(num_points))[None, :]  # random walk RMS scaling factor\n    * (np.sin(x[None, :] - phi)\n       + 0.05 * np.random.randn(num_signal, num_points))  # small random noise\n)\n\n\n# Now we will convert the multiple time series into a histogram. Not only will\n# the hidden signal be more visible, but it is also a much quicker procedure.\n# Linearly interpolate between the points in each time series\nnum_fine = 800\nx_fine = np.linspace(x.min(), x.max(), num_fine)\ny_fine = np.empty((num_series, num_fine), dtype=float)\nfor i in range(num_series):\n    y_fine[i, :] = np.interp(x_fine, x, Y[i, :])\ny_fine = y_fine.flatten()\nx_fine = np.matlib.repmat(x_fine, num_series, 1).flatten()\n\n\n\nImportant!\nThis data is simulated, and may just be random noise! üîä\n\nfig, axes = plt.subplots(figsize=(8, 4), constrained_layout=True)\ncmap = copy(plt.cm.plasma)\ncmap.set_bad(cmap(0))\nh, xedges, yedges = np.histogram2d(x_fine, y_fine, bins=[400, 100])\npcm = axes.pcolormesh(xedges, yedges, h.T, cmap=cmap,\n                         norm=LogNorm(vmax=1.5e2), rasterized=True)\nfig.colorbar(pcm, ax=axes, label=\"# points\", pad=0)\naxes.set_title(\"2d histogram and log color scale\");\n\n","type":"content","url":"/notebook","position":1},{"hierarchy":{"lvl1":"Going the Extra Mile (or Kilometer)"},"type":"lvl1","url":"/demo-regression","position":0},{"hierarchy":{"lvl1":"Going the Extra Mile (or Kilometer)"},"content":"","type":"content","url":"/demo-regression","position":1},{"hierarchy":{"lvl1":"Going the Extra Mile (or Kilometer)","lvl2":"Going the Extra Mile (or Kilometer)"},"type":"lvl2","url":"/demo-regression#going-the-extra-mile-or-kilometer","position":2},{"hierarchy":{"lvl1":"Going the Extra Mile (or Kilometer)","lvl2":"Going the Extra Mile (or Kilometer)"},"content":"Where I‚Äôm from, we use kilometers. In the US, it‚Äôs all miles. When someone says ‚ÄúIt‚Äôs 3 miles away,‚Äù I‚Äôm secretly doing math! Wait, is that close? I try to remember: 1 mile is about HOW MANY kilometers.\n\nIn the end, I just ask, ‚ÄúHow long would it take to walk?‚Äù Problem solved!\n\nBut let‚Äôs say someone gave us some (approximate) data that connects the two.\n\nMiles\n\nKilometers\n\n0\n\n0\n\n7\n\n12\n\n12\n\n20\n\n20\n\n32\n\n30\n\n49\n\nTry to forget you know how to do this - only looking at the data:\n\nCan you see a pattern?\n\nLet‚Äôs plot it and see what we get!\n\n# Import the matplotlib library for plotting\nimport matplotlib.pyplot as plt\n\n# Data for miles and corresponding kilometers\n# Stored in lists\nmiles = [0, 7, 12, 20, 30]\nkm = [0, 12, 20, 32, 49]\n\n# Create a scatter plot\nplt.scatter(miles, km)\n\n# Add labels and title\nplt.xlabel('Miles')\nplt.ylabel('Kilometers')\nplt.title('Miles vs Kilometers')\n\n# Show the plot\nplt.show()\n\n\n\nNow do you see a pattern?\n\nIt looks like a straight line!\n\nimport ipywidgets as widgets\nfrom ipywidgets import interactive\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Rename 'conversion_factor' to represent km per mile\n\ndef plot_line(conversion_factor):\n    plt.figure(figsize=(8,6)) # Increased figure size to accommodate legend\n    plt.scatter(miles, km, label='Data') # Include data points\n    x = np.linspace(- 5, 50, 100)\n    y = conversion_factor * x\n    plt.xlim(-10,60)\n    plt.ylim(-10,60)\n\n    line, = plt.plot(x, y, color='red', label=f'Line: y={conversion_factor:.2f}x')\n    plt.xlabel('Miles')\n    plt.ylabel('Kilometers')\n    plt.title('Miles vs Kilometers with Adjustable Conversion Factor')\n    plt.axvline(color='black')\n    plt.axhline(color='black')\n    plt.grid()\n\n    # Move legend outside the plot\n    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n\n    plt.show()\n\ninteractive(plot_line, conversion_factor=widgets.FloatSlider(value=1 , min=0, max=2, step=0.01, description='Conversion Factor'))\n\n\n\ndef plot_line(conversion_factor):\n    plt.figure(figsize=(8,6)) # Increased figure size to accommodate legend\n    x = np.linspace(- 5, 50, 100)\n    y = conversion_factor * x\n    plt.xlim(-10,60)\n    plt.ylim(-10,60)\n\n    line, = plt.plot(x, y, color='red', label=f'Line: y={conversion_factor:.2f}x')\n    plt.xlabel('Miles')\n    plt.ylabel('Kilometers')\n    plt.title('Miles vs Kilometers with Adjustable Conversion Factor')\n    plt.axvline(color='black')\n    plt.axhline(color='black')\n    plt.grid()\n\n    # Move legend outside the plot\n    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n\n    plt.show()\n\ninteractive(plot_line, conversion_factor=widgets.FloatSlider(value=1 , min=0, max=2, step=0.01, description='Conversion Factor'))\n\n\n\ndef plot_line(conversion_factor):\n    plt.figure(figsize=(8,6)) # Increased figure size to accommodate legend\n    x = np.linspace(- 5, 50, 100)\n    y = conversion_factor * x\n    plt.xlim(-10,60)\n    plt.ylim(-10,60)\n\n    # Calculate total error\n    predicted_km = [conversion_factor * m for m in miles]\n    total_error = sum(abs(a - p) for a, p in zip(km, predicted_km))\n\n    line, = plt.plot(x, y, color='red', label=f'Line: y={conversion_factor:.2f}x, Total Error: {total_error:.2f}')\n    plt.xlabel('Miles')\n    plt.ylabel('Kilometers')\n    plt.title('Miles vs Kilometers with Adjustable Conversion Factor')\n    plt.axvline(color='black')\n    plt.axhline(color='black')\n    plt.grid()\n\n    # Move legend outside the plot\n    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n\n    plt.show()\n\ninteractive(plot_line, conversion_factor=widgets.FloatSlider(value=1 , min=0, max=3, step=0.01, description='Conversion Factor'))\n\n\n\n","type":"content","url":"/demo-regression#going-the-extra-mile-or-kilometer","position":3},{"hierarchy":{"lvl1":"Going the Extra Mile (or Kilometer)","lvl2":"Guessing Without Looking"},"type":"lvl2","url":"/demo-regression#guessing-without-looking","position":4},{"hierarchy":{"lvl1":"Going the Extra Mile (or Kilometer)","lvl2":"Guessing Without Looking"},"content":"We used a slider to visually fit a line to the data. We did this by adjusting the line until the gap between the points and the line was as small as possible to our eyes. But what if we couldn‚Äôt visualize the data at all? How could we find the best fit?\n\nLet‚Äôs explore how we might do this by using the data itself and measuring how ‚Äòwrong‚Äô our guesses are. We‚Äôll try to find the best fit by minimizing the error, just like a computer would!\n\nSuppose we guess a value for the conversion factor from miles to kilometers. For each guess, we can calculate how far off our predictions are from the actual data.\n\nThis difference is called the error.\n\nLet‚Äôs try a few guesses and see how the error changes!\n\ndef check_guess(guess):\n  # Make a list to store our predicted kilometers for each data point\n  predicted_km = []\n  for mile in miles:\n      prediction = guess * mile  # multiply miles by our guess\n      predicted_km.append(prediction)\n\n  # Now let's see how far off each prediction is from the real value\n  errors = []\n  for i in range(len(km)):\n      error = km[i] - predicted_km[i]  # actual minus predicted\n      errors.append(error)\n\n  # Add up all the errors (absolute value, so we don't cancel out)\n  total_error = 0\n\n  # @TODO WE CAN REMOVE THE ABS BELOW AND HAVE STUDENTS POINT THIS OUT!\n  # for error in errors:\n  #     total_error += error\n  for error in errors:\n      total_error += abs(error)\n\n  print(f\"Guess: {guess:.2f}\")\n  print(\"Predicted kilometers:\", predicted_km)\n  print(\"Actual kilometers:\", km)\n  print(\"Errors:\", errors)\n  print(f\"Total error: {total_error:.2f}\")\n\n\n\nguess = 1 # YOUR GUESS HERE\n\ncheck_guess(guess)\n\n\n\nIf our guess isn‚Äôt perfect, we can try adjusting it and see if the error gets smaller. This is the basic idea behind many machine learning algorithms: try, measure error, and improve!\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define a range of possible conversion factors (guesses) to test\nguesses = np.linspace(1.5, 1.8, 30) # Adjusted range\nprint(guesses)\n# Initialize a list to store the total error for each guess\nerrors = []\n\n# Loop through each guess\nfor g in guesses:\n    # Predict the kilometers based on the current guess and the miles data\n    predicted_km = [g * m for m in miles]\n    # Calculate the total absolute error for the current guess\n    # This is the sum of the absolute differences between the actual kilometers and the predicted kilometers\n    total_error = sum(abs(a - p) for a, p in zip(km, predicted_km))\n    # Add the calculated total error to the errors list\n    errors.append(total_error)\n\n\n\n\n# Create a figure for the plot with a specified size\nplt.figure(figsize=(10, 6))\nplt.grid()\n# Plot the relationship between the guesses and their corresponding total errors\nplt.scatter(guesses, errors)\n# Add labels to the x and y axes\nplt.xlabel('Guess for conversion factor)')\nplt.ylabel('Total error')\n# Add a title to the plot\nplt.title('Error vs. Conversion Factor')\n# Display the plot\nplt.show()\n\n\n\n\n\nBy trying different values and measuring the error, we can find the best value without ever seeing the data visually. This is how computers can ‚Äòlearn‚Äô the best fit: by minimizing error!\n\nThis process is at the heart of many machine learning techniques.\n\nQ. What would happen if we don't use the abs() funtion in the error? Are we still minimizing the error?\n\n","type":"content","url":"/demo-regression#guessing-without-looking","position":5},{"hierarchy":{"lvl1":"Going the Extra Mile (or Kilometer)","lvl2":"What Did We Just Do?"},"type":"lvl2","url":"/demo-regression#what-did-we-just-do","position":6},{"hierarchy":{"lvl1":"Going the Extra Mile (or Kilometer)","lvl2":"What Did We Just Do?"},"content":"What we just did was ‚Äòfit‚Äô a line to our data! The conversion factor we found is what we call the slope of the line. The slope tells us how much the output changes for each unit of input.\n\n\n\nNow let‚Äôs try a similar exercise, but with a new example: converting Fahrenheit to Celsius. Another mental math I try to do.\n\nSuppose we have some data:\n\nFahrenheit\n\nCelsius\n\n32\n\n0\n\n50\n\n10\n\n68\n\n20\n\n86\n\n30\n\n104\n\n40\n\nLet‚Äôs see if we can fit a line to this data with a slider like before!\n\nimport ipywidgets as widgets\nfrom ipywidgets import interactive\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Data for Fahrenheit and Celsius\nfahrenheit = [32, 50, 68, 86, 104]\ncelsius = [0, 10, 20, 30, 40]\n\ndef plot_line(slope):\n    plt.figure(figsize=(6,4))\n    plt.scatter(fahrenheit, celsius, label='Data')\n    x = np.linspace(min(fahrenheit), max(fahrenheit), 100)\n    y = slope * x\n    plt.plot(x, y, color='red', label=f'Line: y={slope:.2f}x')\n    plt.xlabel('Fahrenheit')\n    plt.ylabel('Celsius')\n    plt.title('Fahrenheit to Celsius')\n    plt.legend()\n    plt.show()\n\ninteractive(plot_line, slope=widgets.FloatSlider(value=0.5, min=0, max=1, step=0.01, description='Slope'))\n\n\n\nNotice how just changing the slope isn‚Äôt enough to fit the Celsius to Fahrenheit data perfectly. We need another number to shift the line up or down.\n\nThis is called the intercept.\n\ndef plot_line_with_intercept(slope, intercept):\n    plt.figure(figsize=(6,4))\n    plt.scatter(fahrenheit, celsius, label='Data')\n    x = np.linspace(min(fahrenheit), max(fahrenheit), 100)\n    y = slope * x + intercept\n    plt.plot(x, y, color='red', label=f'Line: y={slope:.2f}x + {intercept:.2f}')\n    plt.xlabel('Fahrenheit')\n    plt.ylabel('Celsius')\n    plt.title('Fahrenheit to Celsius: Slope and Intercept')\n    plt.legend()\n    plt.show()\n\ninteractive(plot_line_with_intercept,\n            slope=widgets.FloatSlider(value=0.5, min=0, max=1, step=0.01, description='Slope'),\n            intercept=widgets.FloatSlider(value=-40, min=-60, max=40, step=0.5, description='Intercept'))\n\n\n\nBoth the slope and the intercept are called parameters of our model. A parameter is just a number that we can adjust to help our model fit the data better.\n\n","type":"content","url":"/demo-regression#what-did-we-just-do","position":7},{"hierarchy":{"lvl1":"Going the Extra Mile (or Kilometer)","lvl2":"What have we seen so far?"},"type":"lvl2","url":"/demo-regression#what-have-we-seen-so-far","position":8},{"hierarchy":{"lvl1":"Going the Extra Mile (or Kilometer)","lvl2":"What have we seen so far?"},"content":"Unit conversion:\\text{km} = (\\text{conversion factor}) \\times \\text{miles}\n\nTemperature conversion:\\text{Celsius} = (\\text{slope}) \\times \\text{Fahrenheit} + (\\text{intercept})\n\nBoth of these are examples of linear equations. ### General form  \n\n$$ y = mx + b $$\n\n- $m$: slope (how much $y$ changes when $x$ increases by 1)  \n- $b$: intercept (the value of $y$ when $x = 0$)  \n\n--- ","type":"content","url":"/demo-regression#what-have-we-seen-so-far","position":9},{"hierarchy":{"lvl1":"Going the Extra Mile (or Kilometer)","lvl2":"Our notation going forward"},"type":"lvl2","url":"/demo-regression#our-notation-going-forward","position":10},{"hierarchy":{"lvl1":"Going the Extra Mile (or Kilometer)","lvl2":"Our notation going forward"},"content":"In machine learning we usually write this as:y = wx + b\n\nw: the weight (same role as slope m)\n\nb: the bias (same role as intercept)\n\nFor conversions they are known constants, but in real data we must learn them from examples. We call w and b the parameters of the model.\n\n","type":"content","url":"/demo-regression#our-notation-going-forward","position":11},{"hierarchy":{"lvl1":"WORK IN PROGRESS"},"type":"lvl1","url":"/demo-regression#work-in-progress","position":12},{"hierarchy":{"lvl1":"WORK IN PROGRESS"},"content":"\n\n","type":"content","url":"/demo-regression#work-in-progress","position":13},{"hierarchy":{"lvl1":"WORK IN PROGRESS","lvl2":"Real-World Data: Not Always a Perfect Line"},"type":"lvl2","url":"/demo-regression#real-world-data-not-always-a-perfect-line","position":14},{"hierarchy":{"lvl1":"WORK IN PROGRESS","lvl2":"Real-World Data: Not Always a Perfect Line"},"content":"So far, our examples have been very neat. But real-world data is often messy!\n\nMeasurements can have errors.\n\nThere might be outliers (weird points).\n\nThe relationship might not be exactly a straight line.\n\nLet‚Äôs see what happens if we add a little ‚Äúnoise‚Äù (randomness) to our data.\n\nTry to fit a line visually again. Is it harder? What would you pick as the best line?","type":"content","url":"/demo-regression#real-world-data-not-always-a-perfect-line","position":15}]}